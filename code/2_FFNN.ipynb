{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Group5_FFNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu0UfoGeTAL5"
      },
      "source": [
        "# Preparing the datasets for FFNN"
      ],
      "id": "Pu0UfoGeTAL5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrHeyr_dXVq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65dfa189-cfea-48ea-c7ce-d319b2448cfe"
      },
      "source": [
        "#Load the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import re,string,unicodedata\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,classification_report\n",
        "from sklearn.metrics import recall_score,precision_score,precision_recall_fscore_support"
      ],
      "id": "GrHeyr_dXVq9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVHylO6V4gLe",
        "outputId": "da348674-2acd-4fc0-b941-dcdcee761c9e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "id": "BVHylO6V4gLe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB6W9xrfkB9u"
      },
      "source": [
        "#reading csv file\n",
        "def read_corpus(file):\n",
        "  return pd.read_csv(file)\n",
        "  \n",
        "train_data = '/content/gdrive/MyDrive/NLP_Project/train_data_processed.csv'\n",
        "test_data = '/content/gdrive/MyDrive/NLP_Project/test_data_processed.csv'\n",
        "test_true = '/content/gdrive/MyDrive/NLP_Project/Test_Actual_Final.csv'"
      ],
      "id": "sB6W9xrfkB9u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnx67fgg9hjt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "e6bb5af6-6563-4d1d-e1b9-f7eeb9f32578"
      },
      "source": [
        "#Dataset containing the meme ground truth \n",
        "\n",
        "true_df = read_corpus(test_true)\n",
        "#Extracting the first digit (1, 0 , -1) from Labels \n",
        "\n",
        "true_df['Sentiment'] = true_df['Labels'].str.split('_').str[0]\n",
        "true_df['Sentiment'] = true_df['Sentiment'].astype(int)\n",
        "true_df.head()"
      ],
      "id": "Cnx67fgg9hjt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Image_name</th>\n",
              "      <th>Labels</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>chuck_chuck_norris_meme_10.jpg</td>\n",
              "      <td>1_1100_1100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>dr_evil_NDBB96K.png</td>\n",
              "      <td>1_0100_0200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>misog_2109e457d636565e2e06dce39874c5231e1.jpg</td>\n",
              "      <td>1_1110_1120</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>obama_2691536739_469698809820026_263513986_n.jpg</td>\n",
              "      <td>0_1111_1121</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>kim_threat-kim-jong-un-allegedly-working-on-mu...</td>\n",
              "      <td>0_0000_0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... Sentiment\n",
              "0           0  ...         1\n",
              "1           1  ...         1\n",
              "2           2  ...         1\n",
              "3           3  ...         0\n",
              "4           4  ...         0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiyOE5g5TLQg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "10437f96-3b95-4880-91d8-38ddea8a901f"
      },
      "source": [
        "#Dataset containing the Train data\n",
        "train_df = read_corpus(train_data)\n",
        "\n",
        "train_df.head()"
      ],
      "id": "XiyOE5g5TLQg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_name</th>\n",
              "      <th>text_ocr</th>\n",
              "      <th>text_corrected</th>\n",
              "      <th>humour</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>offensive</th>\n",
              "      <th>motivational</th>\n",
              "      <th>overall_sentiment</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>image_1.jpg</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>hilarious</td>\n",
              "      <td>general</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>very_positive</td>\n",
              "      <td>['look', 'friend', 'lightyear', 'sohalikut', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>image_2.jpeg</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>not_funny</td>\n",
              "      <td>general</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>motivational</td>\n",
              "      <td>very_positive</td>\n",
              "      <td>['best', 'yearchallenge', 'complete', 'less', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>image_3.JPG</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>very_funny</td>\n",
              "      <td>not_sarcastic</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>positive</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>image_4.png</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>very_funny</td>\n",
              "      <td>twisted_meaning</td>\n",
              "      <td>very_offensive</td>\n",
              "      <td>motivational</td>\n",
              "      <td>positive</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>image_5.png</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>hilarious</td>\n",
              "      <td>very_twisted</td>\n",
              "      <td>very_offensive</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>neutral</td>\n",
              "      <td>['year', 'challenge', 'filter', 'hilarious', '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                          processed\n",
              "0           0  ...  ['look', 'friend', 'lightyear', 'sohalikut', '...\n",
              "1           1  ...  ['best', 'yearchallenge', 'complete', 'less', ...\n",
              "2           2  ...  ['sam', 'thorne', 'strippin', 'follow', 'follo...\n",
              "3           3  ...   ['year', 'challenge', 'sweet', 'dee', 'edition']\n",
              "4           4  ...  ['year', 'challenge', 'filter', 'hilarious', '...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a9eea90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1132aaa0-9f73-45e6-d89e-6a5bad368916"
      },
      "source": [
        "train_df['overall_sentiment'].value_counts()"
      ],
      "id": "2a9eea90",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive         3057\n",
              "neutral          2157\n",
              "very_positive    1001\n",
              "negative          469\n",
              "very_negative     146\n",
              "Name: overall_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2eW4ZBYUvDk",
        "outputId": "5fc59fe1-0460-4170-ff4a-0f0d93f31840"
      },
      "source": [
        "#converting categorical to numerical \n",
        "\n",
        "train_df['overall_sentiment'].replace({'very_negative': -1, 'negative': -1, 'neutral': 0, 'positive': 1, 'very_positive': 1}, inplace=True)\n",
        "train_df['overall_sentiment'].value_counts()"
      ],
      "id": "h2eW4ZBYUvDk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    4058\n",
              " 0    2157\n",
              "-1     615\n",
              "Name: overall_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5JAIOrAxFxB",
        "outputId": "10ac1a2c-3f64-444d-d419-0d70293155e4"
      },
      "source": [
        "print(train_df.humour.value_counts())\n",
        "print(train_df.sarcasm.value_counts())\n",
        "print(train_df.offensive.value_counts())\n",
        "print(train_df.motivational.value_counts())"
      ],
      "id": "x5JAIOrAxFxB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "funny         2394\n",
            "very_funny    2176\n",
            "not_funny     1618\n",
            "hilarious      642\n",
            "Name: humour, dtype: int64\n",
            "general            3430\n",
            "not_sarcastic      1516\n",
            "twisted_meaning    1499\n",
            "very_twisted        385\n",
            "Name: sarcasm, dtype: int64\n",
            "not_offensive        2657\n",
            "slight               2536\n",
            "very_offensive       1424\n",
            "hateful_offensive     213\n",
            "Name: offensive, dtype: int64\n",
            "not_motivational    4421\n",
            "motivational        2409\n",
            "Name: motivational, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g067xZdlxZcf"
      },
      "source": [
        "train_df.humour[train_df['humour']!='not_funny']= 1\n",
        "train_df.humour[train_df['humour']=='not_funny']= 0\n",
        "train_df.sarcasm[train_df['sarcasm']!='not_sarcastic']= 1\n",
        "train_df.sarcasm[train_df['sarcasm']=='not_sarcastic']= 0\n",
        "train_df.offensive[train_df['offensive']!='not_offensive']= 1\n",
        "train_df.offensive[train_df['offensive']=='not_offensive']= 0\n",
        "train_df.motivational[train_df['motivational']!='not_motivational']= 1\n",
        "train_df.motivational[train_df['motivational']=='not_motivational']= 0"
      ],
      "id": "g067xZdlxZcf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "AR0BJJ6uyG0o",
        "outputId": "84ac3a9a-c7ea-42ee-e8c1-26a4ae916c23"
      },
      "source": [
        "train_df.head()"
      ],
      "id": "AR0BJJ6uyG0o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_name</th>\n",
              "      <th>text_ocr</th>\n",
              "      <th>text_corrected</th>\n",
              "      <th>humour</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>offensive</th>\n",
              "      <th>motivational</th>\n",
              "      <th>overall_sentiment</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>image_1.jpg</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['look', 'friend', 'lightyear', 'sohalikut', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>image_2.jpeg</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['best', 'yearchallenge', 'complete', 'less', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>image_3.JPG</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>image_4.png</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>image_5.png</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['year', 'challenge', 'filter', 'hilarious', '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                          processed\n",
              "0           0  ...  ['look', 'friend', 'lightyear', 'sohalikut', '...\n",
              "1           1  ...  ['best', 'yearchallenge', 'complete', 'less', ...\n",
              "2           2  ...  ['sam', 'thorne', 'strippin', 'follow', 'follo...\n",
              "3           3  ...   ['year', 'challenge', 'sweet', 'dee', 'edition']\n",
              "4           4  ...  ['year', 'challenge', 'filter', 'hilarious', '...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQcGYlcpySXp",
        "outputId": "08193ffb-8014-41be-c412-5990f4c1f7f2"
      },
      "source": [
        "print(train_df.humour.value_counts())\n",
        "print(train_df.sarcasm.value_counts())\n",
        "print(train_df.offensive.value_counts())\n",
        "print(train_df.motivational.value_counts())"
      ],
      "id": "iQcGYlcpySXp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    5212\n",
            "0    1618\n",
            "Name: humour, dtype: int64\n",
            "1    5314\n",
            "0    1516\n",
            "Name: sarcasm, dtype: int64\n",
            "1    4173\n",
            "0    2657\n",
            "Name: offensive, dtype: int64\n",
            "0    4421\n",
            "1    2409\n",
            "Name: motivational, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMy6wSszkvz4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "1568c5f7-8be9-4d80-ef5d-2b10c5bc1707"
      },
      "source": [
        "#Dataset containing the processed text of test data\n",
        "\n",
        "test_df = read_corpus(test_data)\n",
        "test_df.head()"
      ],
      "id": "zMy6wSszkvz4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Image_name</th>\n",
              "      <th>Image_URL</th>\n",
              "      <th>OCR_extracted_text</th>\n",
              "      <th>corrected_text</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>chuck_chuck_norris_meme_10.jpg</td>\n",
              "      <td>https://gtmemes.com/wp-content/uploads/2019/03...</td>\n",
              "      <td>Some magicians can walk on water  Chuck Norris...</td>\n",
              "      <td>Some magicians can walk on water  Chuck Norris...</td>\n",
              "      <td>['magician', 'walk', 'water', 'chuck', 'norris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>dr_evil_NDBB96K.png</td>\n",
              "      <td>https://i.imgur.com/NDBB96K.png</td>\n",
              "      <td>ONE MILLION DOLLARS made on imgur</td>\n",
              "      <td>ONE MILLION DOLLARS made on imgur</td>\n",
              "      <td>['one', 'million', 'dollar', 'make', 'imgur']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>misog_2109e457d636565e2e06dce39874c5231e1.jpg</td>\n",
              "      <td>https://media0ch-a.akamaihd.net/83/96/9e457d63...</td>\n",
              "      <td>Me: Mom can my friend sleep over? Mom: That's ...</td>\n",
              "      <td>Me: Mom can my friend sleep over? Mom: That's ...</td>\n",
              "      <td>['mom', 'friend', 'sleep', 'mom', 'fine', 'boy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>obama_2691536739_469698809820026_263513986_n.jpg</td>\n",
              "      <td>http://politicalmemes.com/wp-content/uploads/2...</td>\n",
              "      <td>THIS GUY INHERITED A MESS. DID HE WHINE ABOUT ...</td>\n",
              "      <td>THIS GUY INHERITED A MESS. DID HE WHINE ABOUT ...</td>\n",
              "      <td>['guy', 'inherit', 'mess', 'whine', 'foxed', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>kim_threat-kim-jong-un-allegedly-working-on-mu...</td>\n",
              "      <td>https://pics.me.me/threat-kim-jong-un-allegedl...</td>\n",
              "      <td>THREAT: Kim Jong Un allegedly working on multi...</td>\n",
              "      <td>THREAT: Kim Jong Un allegedly working on multi...</td>\n",
              "      <td>['threat', 'kim', 'jong', 'un', 'allegedly', '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                          processed\n",
              "0           0  ...  ['magician', 'walk', 'water', 'chuck', 'norris...\n",
              "1           1  ...      ['one', 'million', 'dollar', 'make', 'imgur']\n",
              "2           2  ...  ['mom', 'friend', 'sleep', 'mom', 'fine', 'boy...\n",
              "3           3  ...  ['guy', 'inherit', 'mess', 'whine', 'foxed', '...\n",
              "4           4  ...  ['threat', 'kim', 'jong', 'un', 'allegedly', '...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruLpJtalMnxe"
      },
      "source": [
        "# Task1 using FFNN "
      ],
      "id": "ruLpJtalMnxe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcdHK_acJGvW"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from gensim.utils import simple_preprocess\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
        "from gensim.parsing.porter import PorterStemmer\n",
        "porter_stemmer = PorterStemmer()      "
      ],
      "id": "RcdHK_acJGvW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ulAExa4MtDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6596df26-3555-4aa6-daf5-2f1131904148"
      },
      "source": [
        "\n",
        "# Use cuda if present\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ],
      "id": "8ulAExa4MtDl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device available for running: \n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBUfTJn2JZS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "23b9caa5-e953-4b6f-e711-a1beb980e34a"
      },
      "source": [
        "train_df_sub = train_df\n",
        "train_df_sub.head()"
      ],
      "id": "cBUfTJn2JZS0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_name</th>\n",
              "      <th>text_ocr</th>\n",
              "      <th>text_corrected</th>\n",
              "      <th>humour</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>offensive</th>\n",
              "      <th>motivational</th>\n",
              "      <th>overall_sentiment</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>image_1.jpg</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['look', 'friend', 'lightyear', 'sohalikut', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>image_2.jpeg</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['best', 'yearchallenge', 'complete', 'less', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>image_3.JPG</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>image_4.png</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>image_5.png</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['year', 'challenge', 'filter', 'hilarious', '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                          processed\n",
              "0           0  ...  ['look', 'friend', 'lightyear', 'sohalikut', '...\n",
              "1           1  ...  ['best', 'yearchallenge', 'complete', 'less', ...\n",
              "2           2  ...  ['sam', 'thorne', 'strippin', 'follow', 'follo...\n",
              "3           3  ...   ['year', 'challenge', 'sweet', 'dee', 'edition']\n",
              "4           4  ...  ['year', 'challenge', 'filter', 'hilarious', '...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QopRikaZH-lO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "f29e350e-6b5a-4021-d25f-ca903bf9d009"
      },
      "source": [
        "#preprocessing train data\n",
        "def preprocess(train_df_sub, label):\n",
        "  # Tokenize the text column to get the new column 'tokenized_text'\n",
        "  train_df_sub['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in train_df_sub[label]] \n",
        "\n",
        "  #remove stop words\n",
        "  train_df_sub['stop_tokens'] = [[remove_stopwords(word) for word in tokens] for tokens in train_df_sub['tokenized_text'] ]\n",
        "\n",
        "  #remove punctuations\n",
        "  train_df_sub['rem_punct_tokens'] = [[word.lower() for word in tokens if word.isalpha()] for tokens in train_df_sub['stop_tokens'] ]\n",
        "\n",
        "  # Get the stemmed_tokens\n",
        "  train_df_sub['pre_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in train_df_sub['rem_punct_tokens'] ]\n",
        "  \n",
        "  return train_df_sub\n",
        "  #train_df_sub['pre_tokens'].head(10)\n",
        "\n",
        "train_df_sub = preprocess(train_df_sub, 'text_ocr')\n",
        "\n",
        "train_df_sub.to_csv('train_data_processed.csv')\n",
        "\n",
        "train_df_sub.head()"
      ],
      "id": "QopRikaZH-lO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_name</th>\n",
              "      <th>text_ocr</th>\n",
              "      <th>text_corrected</th>\n",
              "      <th>humour</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>offensive</th>\n",
              "      <th>motivational</th>\n",
              "      <th>overall_sentiment</th>\n",
              "      <th>processed</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>stop_tokens</th>\n",
              "      <th>rem_punct_tokens</th>\n",
              "      <th>pre_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>image_1.jpg</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['look', 'friend', 'lightyear', 'sohalikut', '...</td>\n",
              "      <td>[look, there, my, friend, lightyear, now, all,...</td>\n",
              "      <td>[look, , , friend, lightyear, , , sohalikut, t...</td>\n",
              "      <td>[look, friend, lightyear, sohalikut, trend, pl...</td>\n",
              "      <td>[look, friend, lightyear, sohalikut, trend, pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>image_2.jpeg</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['best', 'yearchallenge', 'complete', 'less', ...</td>\n",
              "      <td>[the, best, of, yearchallenge, completed, in, ...</td>\n",
              "      <td>[, best, , yearchallenge, completed, , , , yea...</td>\n",
              "      <td>[best, yearchallenge, completed, years, kudus,...</td>\n",
              "      <td>[best, yearchalleng, complet, year, kudu, nare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>image_3.JPG</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "      <td>[sam, thorne, strippin, follow, follow, saw, e...</td>\n",
              "      <td>[sam, thorne, strippin, follow, follow, saw, ,...</td>\n",
              "      <td>[sam, thorne, strippin, follow, follow, saw, p...</td>\n",
              "      <td>[sam, thorn, strippin, follow, follow, saw, po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>image_4.png</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "      <td>[year, challenge, sweet, dee, edition]</td>\n",
              "      <td>[year, challenge, sweet, dee, edition]</td>\n",
              "      <td>[year, challenge, sweet, dee, edition]</td>\n",
              "      <td>[year, challeng, sweet, dee, edit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>image_5.png</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['year', 'challenge', 'filter', 'hilarious', '...</td>\n",
              "      <td>[year, challenge, with, no, filter, hilarious,...</td>\n",
              "      <td>[year, challenge, , , filter, hilarious, year,...</td>\n",
              "      <td>[year, challenge, filter, hilarious, year, cha...</td>\n",
              "      <td>[year, challeng, filter, hilari, year, challen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                         pre_tokens\n",
              "0           0  ...  [look, friend, lightyear, sohalikut, trend, pl...\n",
              "1           1  ...  [best, yearchalleng, complet, year, kudu, nare...\n",
              "2           2  ...  [sam, thorn, strippin, follow, follow, saw, po...\n",
              "3           3  ...                 [year, challeng, sweet, dee, edit]\n",
              "4           4  ...  [year, challeng, filter, hilari, year, challen...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O91IPzwU5DTy"
      },
      "source": [
        "#The FFNN model\n",
        "\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        \n",
        "        # Linear function 1: \n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        # Non-linearity 1\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Non-linearity 2\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Linear function 2 \n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)  \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.l3(out)\n",
        "        return out"
      ],
      "id": "O91IPzwU5DTy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NIhe_VxAFGp",
        "outputId": "a9955845-d94c-49f5-9f3b-fda3beae7d93"
      },
      "source": [
        "#Creating a dictionary of words \n",
        "\n",
        "from gensim import corpora\n",
        "# Function to return the dictionary either with padding word or without padding\n",
        "def make_dict(train_df_sub, padding=True):\n",
        "    if padding:\n",
        "        print(\"Dictionary with padded token added\")\n",
        "        review_dict = corpora.Dictionary([['pad']])\n",
        "        review_dict.add_documents(train_df_sub['pre_tokens'])\n",
        "    else:\n",
        "        print(\"Dictionary without padding\")\n",
        "        review_dict = corpora.Dictionary(train_df_sub['pre_tokens'])\n",
        "    return review_dict\n",
        "\n",
        "# Make the dictionary without padding for the basic models\n",
        "review_dict = make_dict(train_df_sub, padding=False)"
      ],
      "id": "1NIhe_VxAFGp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary without padding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh8qDkVmHAfS"
      },
      "source": [
        "#creating bag of words \n",
        "\n",
        "VOCAB_SIZE = len(review_dict)\n",
        "\n",
        "# Function to make bow vector to be used as input to network\n",
        "def make_bow_vector(review_dict, sentence):\n",
        "    vec = torch.zeros(VOCAB_SIZE, dtype=torch.float64, device=device)\n",
        "    for word in sentence:\n",
        "        vec[review_dict.token2id[word]] += 1\n",
        "    return vec.view(1, -1).float()\n",
        "\n",
        "def make_bow_vector1(review_dict, sentence):\n",
        "    vec = torch.zeros(VOCAB_SIZE, dtype=torch.float64, device=device)\n",
        "    for word in sentence:\n",
        "      if word in review_dict.keys():\n",
        "        vec[review_dict.token2id[word]] += 1\n",
        "    return vec.view(1, -1).float()"
      ],
      "id": "Uh8qDkVmHAfS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1vDn4kbNxcF"
      },
      "source": [
        "# Function to get the output tensor\n",
        "def make_target(label):\n",
        "    if label == -1:\n",
        "        return torch.tensor([2], dtype=torch.long, device=device)\n",
        "    elif label == 0:\n",
        "        return torch.tensor([0], dtype=torch.long, device=device)\n",
        "    else:\n",
        "        return torch.tensor([1], dtype=torch.long, device=device)"
      ],
      "id": "i1vDn4kbNxcF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLWt9r7_N_-9"
      },
      "source": [
        "#Training the FFNN model\n",
        "\n",
        "VOCAB_SIZE = len(review_dict)\n",
        "\n",
        "input_size = VOCAB_SIZE\n",
        "hidden_size = 500\n",
        "num_classes = 3\n",
        "num_epochs = 100\n",
        "\n",
        "ff_nn_bow_model = FeedforwardNeuralNetModel(input_size, hidden_size, num_classes)\n",
        "ff_nn_bow_model.to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(ff_nn_bow_model.parameters(), lr=0.01)\n",
        "#optimizer = torch.optim.Adam(ff_nn_bow_model.parameters(), lr=0.001)"
      ],
      "id": "zLWt9r7_N_-9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5guhKjMPT4r"
      },
      "source": [
        "\n",
        "X_train = train_df_sub[['pre_tokens']]\n",
        "sentiment = train_df_sub['overall_sentiment']\n",
        "\n",
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch+1) % 25 == 0:\n",
        "        print(\"Epoch completed: \" + str(epoch+1))\n",
        "    train_loss = 0\n",
        "    for index, row in X_train.iterrows():\n",
        "        # Clearing the accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make the bag of words vector for stemmed tokens \n",
        "        bow_vec = make_bow_vector(review_dict, row['pre_tokens'])\n",
        "       \n",
        "        # Forward pass to get output\n",
        "        probs = ff_nn_bow_model(bow_vec)\n",
        "        \n",
        "\n",
        "        # Get the target label\n",
        "        lab = train_df_sub['overall_sentiment'][index]\n",
        "        target = make_target(lab)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = loss_function(probs, target)\n",
        "        # Accumulating the loss over time\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()"
      ],
      "id": "L5guhKjMPT4r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c-mCoFVayMx"
      },
      "source": [
        "test_df_sub = test_df\n",
        "#test_df_sub"
      ],
      "id": "5c-mCoFVayMx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKiWkD_HYE4n"
      },
      "source": [
        "#Preprocessing of test data\n",
        "test_df_sub = preprocess(test_df_sub, 'OCR_extracted_text')\n",
        "test_df_sub.to_csv('test_data_processed.csv')"
      ],
      "id": "SKiWkD_HYE4n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddP6Sy2_jniI"
      },
      "source": [
        "test_df_sub.head()"
      ],
      "id": "ddP6Sy2_jniI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgOjC0WiZYdJ",
        "outputId": "c3846284-b86e-4ffe-b8b5-dab24797f1bb"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "bow_ff_nn_predictions = []\n",
        "original_lables_ff_bow = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for index, row in test_df_sub.iterrows():\n",
        "        bow_vec = make_bow_vector1(review_dict, row['pre_tokens'])\n",
        "        probs = ff_nn_bow_model(bow_vec)\n",
        "        bow_ff_nn_predictions.append(torch.argmax(probs, dim=1).cpu().numpy()[0])\n",
        "        original_lables_ff_bow.append(make_target(true_df['Sentiment'][index]).cpu().numpy()[0])\n",
        "print(classification_report(original_lables_ff_bow,bow_ff_nn_predictions))\n",
        "print(' Test accuracy is {}'.format(accuracy_score(original_lables_ff_bow,bow_ff_nn_predictions) * 100))\n",
        "print(\" F1 Score: {:.2f}\".format(f1_score(original_lables_ff_bow,bow_ff_nn_predictions, average='macro') * 100))\n",
        "print(\" Precision Score: {:.2f}\".format(precision_score(original_lables_ff_bow,bow_ff_nn_predictions, average='macro') * 100))\n",
        "print(\" Recall Score: {:.2f}\".format(recall_score(original_lables_ff_bow,bow_ff_nn_predictions, average='macro') * 100))\n",
        "print(\"\\n\")"
      ],
      "id": "CgOjC0WiZYdJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       586\n",
            "           1       0.59      1.00      0.74      1101\n",
            "           2       0.00      0.00      0.00       172\n",
            "\n",
            "    accuracy                           0.59      1859\n",
            "   macro avg       0.20      0.33      0.25      1859\n",
            "weighted avg       0.35      0.59      0.44      1859\n",
            "\n",
            " Test accuracy is 59.225389994620755\n",
            " F1 Score: 24.80\n",
            " Precision Score: 19.74\n",
            " Recall Score: 33.33\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uWmcWQpEzUs"
      },
      "source": [
        "# Task2 using FFNN"
      ],
      "id": "7uWmcWQpEzUs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "F6k5dDW_4-bX",
        "outputId": "3dbae34a-f9ae-438b-b28b-bef152cde6a6"
      },
      "source": [
        "train_df_sub.head()"
      ],
      "id": "F6k5dDW_4-bX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_name</th>\n",
              "      <th>text_ocr</th>\n",
              "      <th>text_corrected</th>\n",
              "      <th>humour</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>offensive</th>\n",
              "      <th>motivational</th>\n",
              "      <th>overall_sentiment</th>\n",
              "      <th>processed</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>stop_tokens</th>\n",
              "      <th>rem_punct_tokens</th>\n",
              "      <th>pre_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>image_1.jpg</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['look', 'friend', 'lightyear', 'sohalikut', '...</td>\n",
              "      <td>[look, there, my, friend, lightyear, now, all,...</td>\n",
              "      <td>[look, , , friend, lightyear, , , sohalikut, t...</td>\n",
              "      <td>[look, friend, lightyear, sohalikut, trend, pl...</td>\n",
              "      <td>[look, friend, lightyear, sohalikut, trend, pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>image_2.jpeg</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['best', 'yearchallenge', 'complete', 'less', ...</td>\n",
              "      <td>[the, best, of, yearchallenge, completed, in, ...</td>\n",
              "      <td>[, best, , yearchallenge, completed, , , , yea...</td>\n",
              "      <td>[best, yearchallenge, completed, years, kudus,...</td>\n",
              "      <td>[best, yearchalleng, complet, year, kudu, nare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>image_3.JPG</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "      <td>[sam, thorne, strippin, follow, follow, saw, e...</td>\n",
              "      <td>[sam, thorne, strippin, follow, follow, saw, ,...</td>\n",
              "      <td>[sam, thorne, strippin, follow, follow, saw, p...</td>\n",
              "      <td>[sam, thorn, strippin, follow, follow, saw, po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>image_4.png</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "      <td>[year, challenge, sweet, dee, edition]</td>\n",
              "      <td>[year, challenge, sweet, dee, edition]</td>\n",
              "      <td>[year, challenge, sweet, dee, edition]</td>\n",
              "      <td>[year, challeng, sweet, dee, edit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>image_5.png</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['year', 'challenge', 'filter', 'hilarious', '...</td>\n",
              "      <td>[year, challenge, with, no, filter, hilarious,...</td>\n",
              "      <td>[year, challenge, , , filter, hilarious, year,...</td>\n",
              "      <td>[year, challenge, filter, hilarious, year, cha...</td>\n",
              "      <td>[year, challeng, filter, hilari, year, challen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                         pre_tokens\n",
              "0           0  ...  [look, friend, lightyear, sohalikut, trend, pl...\n",
              "1           1  ...  [best, yearchalleng, complet, year, kudu, nare...\n",
              "2           2  ...  [sam, thorn, strippin, follow, follow, saw, po...\n",
              "3           3  ...                 [year, challeng, sweet, dee, edit]\n",
              "4           4  ...  [year, challeng, filter, hilari, year, challen...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUkl5TG28zG5"
      },
      "source": [
        "# Function to get the output tensor\n",
        "def make_target_2(label):\n",
        "    if label == 1:\n",
        "        return torch.tensor([1], dtype=torch.long, device=device)\n",
        "    elif label == 0:\n",
        "        return torch.tensor([0], dtype=torch.long, device=device)"
      ],
      "id": "OUkl5TG28zG5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvuxzqg0E24I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822cfb68-8339-4402-b85a-8a9436bf3cc6"
      },
      "source": [
        "X_train = train_df_sub[['pre_tokens']]\n",
        "\n",
        "categories={'humour':0,'sarcasm':1,'offensive':2,'motivational':3}\n",
        "\n",
        "for category in categories.keys():\n",
        "  print('******Processing {} category...******'.format(category))\n",
        "\n",
        "  # Start training\n",
        "  for epoch in range(num_epochs):\n",
        "      #if (epoch+1) % 25 == 0:\n",
        "      #   print(\"Epoch completed: \" + str(epoch+1))\n",
        "      train_loss = 0\n",
        "      for index, row in X_train.iterrows():\n",
        "          # Clearing the accumulated gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Make the bag of words vector for stemmed tokens \n",
        "          bow_vec = make_bow_vector(review_dict, row['pre_tokens'])\n",
        "        \n",
        "          # Forward pass to get output\n",
        "          probs = ff_nn_bow_model(bow_vec)\n",
        "          \n",
        "          # Get the target label\n",
        "          lab = train_df_sub[category][index]\n",
        "          target = make_target_2(lab)\n",
        "          #print(lab)\n",
        "          #print(target)\n",
        "\n",
        "          # Calculate Loss: softmax --> cross entropy loss\n",
        "          loss = loss_function(probs, target)\n",
        "          # Accumulating the loss over time\n",
        "          train_loss += loss.item()\n",
        "\n",
        "          # Getting gradients w.r.t. parameters\n",
        "          loss.backward()\n",
        "\n",
        "          # Updating parameters\n",
        "          optimizer.step()\n",
        "\n",
        "  bow_ff_nn_predictions = []\n",
        "  original_lables_ff_bow = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for index, row in test_df_sub.iterrows():\n",
        "          bow_vec = make_bow_vector1(review_dict, row['pre_tokens'])\n",
        "          probs = ff_nn_bow_model(bow_vec)\n",
        "          bow_ff_nn_predictions.append(torch.argmax(probs, dim=1).cpu().numpy()[0])\n",
        "          lab = true_df['Labels'].str.split('_').str[1].str[categories[category]][index]\n",
        "          lab = int(lab)\n",
        "          #print(lab)\n",
        "          original_lables_ff_bow.append(make_target_2(lab).cpu().numpy()[0])\n",
        "  print(classification_report(original_lables_ff_bow,bow_ff_nn_predictions))\n",
        "  print(' Test accuracy is {}'.format(accuracy_score(original_lables_ff_bow,bow_ff_nn_predictions) * 100))\n",
        "  print(\" F1 Score: {:.2f}\".format(f1_score(original_lables_ff_bow,bow_ff_nn_predictions, average='macro') * 100))\n",
        "  print(\" Precision Score: {:.2f}\".format(precision_score(original_lables_ff_bow,bow_ff_nn_predictions, average='macro') * 100))\n",
        "  print(\" Recall Score: {:.2f}\".format(recall_score(original_lables_ff_bow,bow_ff_nn_predictions, average='macro') * 100))\n",
        "  print(\"\\n\")"
      ],
      "id": "wvuxzqg0E24I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******Processing humour category...******\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       443\n",
            "           1       0.76      1.00      0.86      1416\n",
            "\n",
            "    accuracy                           0.76      1859\n",
            "   macro avg       0.38      0.50      0.43      1859\n",
            "weighted avg       0.58      0.76      0.66      1859\n",
            "\n",
            " Test accuracy is 76.16998386229156\n",
            " F1 Score: 43.24\n",
            " Precision Score: 38.08\n",
            " Recall Score: 50.00\n",
            "\n",
            "\n",
            "******Processing sarcasm category...******\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       418\n",
            "           1       0.78      1.00      0.87      1441\n",
            "\n",
            "    accuracy                           0.78      1859\n",
            "   macro avg       0.39      0.50      0.44      1859\n",
            "weighted avg       0.60      0.78      0.68      1859\n",
            "\n",
            " Test accuracy is 77.51479289940828\n",
            " F1 Score: 43.67\n",
            " Precision Score: 38.76\n",
            " Recall Score: 50.00\n",
            "\n",
            "\n",
            "******Processing offensive category...******\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       700\n",
            "           1       0.62      1.00      0.77      1159\n",
            "\n",
            "    accuracy                           0.62      1859\n",
            "   macro avg       0.31      0.50      0.38      1859\n",
            "weighted avg       0.39      0.62      0.48      1859\n",
            "\n",
            " Test accuracy is 62.345346960731575\n",
            " F1 Score: 38.40\n",
            " Precision Score: 31.17\n",
            " Recall Score: 50.00\n",
            "\n",
            "\n",
            "******Processing motivational category...******\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1176\n",
            "           1       0.37      1.00      0.54       683\n",
            "\n",
            "    accuracy                           0.37      1859\n",
            "   macro avg       0.18      0.50      0.27      1859\n",
            "weighted avg       0.13      0.37      0.20      1859\n",
            "\n",
            " Test accuracy is 36.74018289402905\n",
            " F1 Score: 26.87\n",
            " Precision Score: 18.37\n",
            " Recall Score: 50.00\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}