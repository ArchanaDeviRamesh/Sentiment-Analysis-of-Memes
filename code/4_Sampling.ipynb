{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "NLP_project_Group5_Sampling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0104c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7bccef-a25c-4a7c-902f-2a2a27b6ce5c"
      },
      "source": [
        "#Importing all the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler, SequentialSampler)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "b0104c8a",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QloW-EeQWese",
        "outputId": "d44f64df-e536-46c5-80f3-8a0558d73e9b"
      },
      "source": [
        "#Downloading NLTK libraries\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "id": "QloW-EeQWese",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ulAExa4MtDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ea2b47-35de-4ef6-fe9e-e5ec09ca2b87"
      },
      "source": [
        "# Use cuda if present\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ],
      "id": "8ulAExa4MtDl",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device available for running: \n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIOzBU-ODW9T"
      },
      "source": [
        "#Root folder for data files (for storage and retrieval)\n",
        "GDRIVE_PROJECT_FOLDER = '/content/gdrive/MyDrive/NLP_Project/'"
      ],
      "id": "hIOzBU-ODW9T",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R8N0p_mSbg_",
        "outputId": "646f8ad4-9097-4887-9e31-ef5a9a972916"
      },
      "source": [
        "#Mount the google drive to access data files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "id": "-R8N0p_mSbg_",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB6W9xrfkB9u"
      },
      "source": [
        "#Path variables for the train and test data files\n",
        "train_data = GDRIVE_PROJECT_FOLDER+'train_data_processed.csv'\n",
        "test_data = GDRIVE_PROJECT_FOLDER+'test_data_processed.csv'\n",
        "test_true = GDRIVE_PROJECT_FOLDER+'Test_Actual_Final.csv'"
      ],
      "id": "sB6W9xrfkB9u",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Cnx67fgg9hjt",
        "outputId": "2e3e4d2c-4e89-426f-df7e-8ccf7cec1c98"
      },
      "source": [
        "#Dataset containing the meme ground truth \n",
        "true_df = pd.read_csv(test_true)\n",
        "true_df.head()"
      ],
      "id": "Cnx67fgg9hjt",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Image_name</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>chuck_chuck_norris_meme_10.jpg</td>\n",
              "      <td>1_1100_1100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>dr_evil_NDBB96K.png</td>\n",
              "      <td>1_0100_0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>misog_2109e457d636565e2e06dce39874c5231e1.jpg</td>\n",
              "      <td>1_1110_1120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>obama_2691536739_469698809820026_263513986_n.jpg</td>\n",
              "      <td>0_1111_1121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>kim_threat-kim-jong-un-allegedly-working-on-mu...</td>\n",
              "      <td>0_0000_0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                         Image_name       Labels\n",
              "0           0                     chuck_chuck_norris_meme_10.jpg  1_1100_1100\n",
              "1           1                                dr_evil_NDBB96K.png  1_0100_0200\n",
              "2           2      misog_2109e457d636565e2e06dce39874c5231e1.jpg  1_1110_1120\n",
              "3           3   obama_2691536739_469698809820026_263513986_n.jpg  0_1111_1121\n",
              "4           4  kim_threat-kim-jong-un-allegedly-working-on-mu...  0_0000_0000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RBuzPUmo-B2L",
        "outputId": "928a3a4d-963f-4709-ac73-2aca8618a837"
      },
      "source": [
        "#Extracting the first digit (1, 0 , -1) from Labels \n",
        "true_df['Sentiment'] = true_df['Labels'].str.split('_').str[0]\n",
        "true_df['Sentiment'] = true_df['Sentiment'].astype(int)\n",
        "true_df.head()"
      ],
      "id": "RBuzPUmo-B2L",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Image_name</th>\n",
              "      <th>Labels</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>chuck_chuck_norris_meme_10.jpg</td>\n",
              "      <td>1_1100_1100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>dr_evil_NDBB96K.png</td>\n",
              "      <td>1_0100_0200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>misog_2109e457d636565e2e06dce39874c5231e1.jpg</td>\n",
              "      <td>1_1110_1120</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>obama_2691536739_469698809820026_263513986_n.jpg</td>\n",
              "      <td>0_1111_1121</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>kim_threat-kim-jong-un-allegedly-working-on-mu...</td>\n",
              "      <td>0_0000_0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... Sentiment\n",
              "0           0  ...         1\n",
              "1           1  ...         1\n",
              "2           2  ...         1\n",
              "3           3  ...         0\n",
              "4           4  ...         0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "XiyOE5g5TLQg",
        "outputId": "8df339f7-5180-4dfc-8634-ee706d1dd560"
      },
      "source": [
        "#Dataset containing the Train data\n",
        "train_df = pd.read_csv(train_data, converters={'pre_tokens': eval, 'processed': eval})\n",
        "train_df.head()"
      ],
      "id": "XiyOE5g5TLQg",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>image_name</th>\n",
              "      <th>text_ocr</th>\n",
              "      <th>text_corrected</th>\n",
              "      <th>humour</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>offensive</th>\n",
              "      <th>motivational</th>\n",
              "      <th>overall_sentiment</th>\n",
              "      <th>processed</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>stop_tokens</th>\n",
              "      <th>rem_punct_tokens</th>\n",
              "      <th>pre_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>image_1.jpg</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[look, friend, lightyear, sohalikut, trend, pl...</td>\n",
              "      <td>['look', 'there', 'my', 'friend', 'lightyear',...</td>\n",
              "      <td>['look', '', '', 'friend', 'lightyear', '', ''...</td>\n",
              "      <td>['look', 'friend', 'lightyear', 'sohalikut', '...</td>\n",
              "      <td>[look, friend, lightyear, sohalikut, trend, pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>image_2.jpeg</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[best, yearchallenge, complete, less, year, ku...</td>\n",
              "      <td>['the', 'best', 'of', 'yearchallenge', 'comple...</td>\n",
              "      <td>['', 'best', '', 'yearchallenge', 'completed',...</td>\n",
              "      <td>['best', 'yearchallenge', 'completed', 'years'...</td>\n",
              "      <td>[best, yearchalleng, complet, year, kudu, nare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>image_3.JPG</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[sam, thorne, strippin, follow, follow, saw, e...</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "      <td>[sam, thorn, strippin, follow, follow, saw, po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>image_4.png</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[year, challenge, sweet, dee, edition]</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "      <td>[year, challeng, sweet, dee, edit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>image_5.png</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[year, challenge, filter, hilarious, year, cha...</td>\n",
              "      <td>['year', 'challenge', 'with', 'no', 'filter', ...</td>\n",
              "      <td>['year', 'challenge', '', '', 'filter', 'hilar...</td>\n",
              "      <td>['year', 'challenge', 'filter', 'hilarious', '...</td>\n",
              "      <td>[year, challeng, filter, hilari, year, challen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                         pre_tokens\n",
              "0           0  ...  [look, friend, lightyear, sohalikut, trend, pl...\n",
              "1           1  ...  [best, yearchalleng, complet, year, kudu, nare...\n",
              "2           2  ...  [sam, thorn, strippin, follow, follow, saw, po...\n",
              "3           3  ...                 [year, challeng, sweet, dee, edit]\n",
              "4           4  ...  [year, challeng, filter, hilari, year, challen...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a9eea90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80f43ee-c600-4764-c992-cfaea557f4fc"
      },
      "source": [
        "#Checking the class labels balance in training dataset for task 1 (identifying meme as positive/negative/neutral - (1/-1/0))\n",
        "train_df['overall_sentiment'].value_counts()"
      ],
      "id": "2a9eea90",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    4058\n",
              " 0    2157\n",
              "-1     615\n",
              "Name: overall_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "zMy6wSszkvz4",
        "outputId": "28eaa65d-4c28-4665-9f42-885a3c0f582b"
      },
      "source": [
        "#Dataset containing the processed text of test data\n",
        "test_df = pd.read_csv(test_data, converters={'pre_tokens': eval, 'processed': eval})\n",
        "test_df.head()"
      ],
      "id": "zMy6wSszkvz4",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Image_name</th>\n",
              "      <th>Image_URL</th>\n",
              "      <th>OCR_extracted_text</th>\n",
              "      <th>corrected_text</th>\n",
              "      <th>processed</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>stop_tokens</th>\n",
              "      <th>rem_punct_tokens</th>\n",
              "      <th>pre_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>chuck_chuck_norris_meme_10.jpg</td>\n",
              "      <td>https://gtmemes.com/wp-content/uploads/2019/03...</td>\n",
              "      <td>Some magicians can walk on water  Chuck Norris...</td>\n",
              "      <td>Some magicians can walk on water  Chuck Norris...</td>\n",
              "      <td>[magician, walk, water, chuck, norris, swim, l...</td>\n",
              "      <td>['some', 'magicians', 'can', 'walk', 'on', 'wa...</td>\n",
              "      <td>['', 'magicians', '', 'walk', '', 'water', 'ch...</td>\n",
              "      <td>['magicians', 'walk', 'water', 'chuck', 'norri...</td>\n",
              "      <td>[magician, walk, water, chuck, norri, swim, land]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>dr_evil_NDBB96K.png</td>\n",
              "      <td>https://i.imgur.com/NDBB96K.png</td>\n",
              "      <td>ONE MILLION DOLLARS made on imgur</td>\n",
              "      <td>ONE MILLION DOLLARS made on imgur</td>\n",
              "      <td>[one, million, dollar, make, imgur]</td>\n",
              "      <td>['one', 'million', 'dollars', 'made', 'on', 'i...</td>\n",
              "      <td>['', 'million', 'dollars', '', '', 'imgur']</td>\n",
              "      <td>['million', 'dollars', 'imgur']</td>\n",
              "      <td>[million, dollar, imgur]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>misog_2109e457d636565e2e06dce39874c5231e1.jpg</td>\n",
              "      <td>https://media0ch-a.akamaihd.net/83/96/9e457d63...</td>\n",
              "      <td>Me: Mom can my friend sleep over? Mom: That's ...</td>\n",
              "      <td>Me: Mom can my friend sleep over? Mom: That's ...</td>\n",
              "      <td>[mom, friend, sleep, mom, fine, boy, growingup...</td>\n",
              "      <td>['me', 'mom', 'can', 'my', 'friend', 'sleep', ...</td>\n",
              "      <td>['', 'mom', '', '', 'friend', 'sleep', '', 'mo...</td>\n",
              "      <td>['mom', 'friend', 'sleep', 'mom', 'fine', 'boy...</td>\n",
              "      <td>[mom, friend, sleep, mom, fine, boi, growingup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>obama_2691536739_469698809820026_263513986_n.jpg</td>\n",
              "      <td>http://politicalmemes.com/wp-content/uploads/2...</td>\n",
              "      <td>THIS GUY INHERITED A MESS. DID HE WHINE ABOUT ...</td>\n",
              "      <td>THIS GUY INHERITED A MESS. DID HE WHINE ABOUT ...</td>\n",
              "      <td>[guy, inherit, mess, whine, foxed, thing, guy,...</td>\n",
              "      <td>['this', 'guy', 'inherited', 'mess', 'did', 'h...</td>\n",
              "      <td>['', 'guy', 'inherited', 'mess', '', '', 'whin...</td>\n",
              "      <td>['guy', 'inherited', 'mess', 'whine', 'foxed',...</td>\n",
              "      <td>[gui, inherit, mess, whine, fox, thing, gui, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>kim_threat-kim-jong-un-allegedly-working-on-mu...</td>\n",
              "      <td>https://pics.me.me/threat-kim-jong-un-allegedl...</td>\n",
              "      <td>THREAT: Kim Jong Un allegedly working on multi...</td>\n",
              "      <td>THREAT: Kim Jong Un allegedly working on multi...</td>\n",
              "      <td>[threat, kim, jong, un, allegedly, work, multi...</td>\n",
              "      <td>['threat', 'kim', 'jong', 'un', 'allegedly', '...</td>\n",
              "      <td>['threat', 'kim', 'jong', '', 'allegedly', 'wo...</td>\n",
              "      <td>['threat', 'kim', 'jong', 'allegedly', 'workin...</td>\n",
              "      <td>[threat, kim, jong, allegedli, work, multipl, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                         pre_tokens\n",
              "0           0  ...  [magician, walk, water, chuck, norri, swim, land]\n",
              "1           1  ...                           [million, dollar, imgur]\n",
              "2           2  ...  [mom, friend, sleep, mom, fine, boi, growingup...\n",
              "3           3  ...  [gui, inherit, mess, whine, fox, thing, gui, f...\n",
              "4           4  ...  [threat, kim, jong, allegedli, work, multipl, ...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBUfTJn2JZS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "2d266bc9-e68b-4c60-d434-6f0852aa334b"
      },
      "source": [
        "#Creating a duplicate copy of train dataframe, so that modifications can be done in copy df if needed\n",
        "train_df_sub = train_df\n",
        "train_df_sub.head()"
      ],
      "id": "cBUfTJn2JZS0",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>image_name</th>\n",
              "      <th>text_ocr</th>\n",
              "      <th>text_corrected</th>\n",
              "      <th>humour</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>offensive</th>\n",
              "      <th>motivational</th>\n",
              "      <th>overall_sentiment</th>\n",
              "      <th>processed</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>stop_tokens</th>\n",
              "      <th>rem_punct_tokens</th>\n",
              "      <th>pre_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>image_1.jpg</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[look, friend, lightyear, sohalikut, trend, pl...</td>\n",
              "      <td>['look', 'there', 'my', 'friend', 'lightyear',...</td>\n",
              "      <td>['look', '', '', 'friend', 'lightyear', '', ''...</td>\n",
              "      <td>['look', 'friend', 'lightyear', 'sohalikut', '...</td>\n",
              "      <td>[look, friend, lightyear, sohalikut, trend, pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>image_2.jpeg</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[best, yearchallenge, complete, less, year, ku...</td>\n",
              "      <td>['the', 'best', 'of', 'yearchallenge', 'comple...</td>\n",
              "      <td>['', 'best', '', 'yearchallenge', 'completed',...</td>\n",
              "      <td>['best', 'yearchallenge', 'completed', 'years'...</td>\n",
              "      <td>[best, yearchalleng, complet, year, kudu, nare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>image_3.JPG</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[sam, thorne, strippin, follow, follow, saw, e...</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "      <td>['sam', 'thorne', 'strippin', 'follow', 'follo...</td>\n",
              "      <td>[sam, thorn, strippin, follow, follow, saw, po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>image_4.png</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[year, challenge, sweet, dee, edition]</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "      <td>['year', 'challenge', 'sweet', 'dee', 'edition']</td>\n",
              "      <td>[year, challeng, sweet, dee, edit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>image_5.png</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[year, challenge, filter, hilarious, year, cha...</td>\n",
              "      <td>['year', 'challenge', 'with', 'no', 'filter', ...</td>\n",
              "      <td>['year', 'challenge', '', '', 'filter', 'hilar...</td>\n",
              "      <td>['year', 'challenge', 'filter', 'hilarious', '...</td>\n",
              "      <td>[year, challeng, filter, hilari, year, challen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                         pre_tokens\n",
              "0           0  ...  [look, friend, lightyear, sohalikut, trend, pl...\n",
              "1           1  ...  [best, yearchalleng, complet, year, kudu, nare...\n",
              "2           2  ...  [sam, thorn, strippin, follow, follow, saw, po...\n",
              "3           3  ...                 [year, challeng, sweet, dee, edit]\n",
              "4           4  ...  [year, challeng, filter, hilari, year, challen...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzbTVa99v_s_"
      },
      "source": [
        "# Handling class imbalance using Random Oversampling and SMOTE techniques\n",
        "# with Logistic Regression model"
      ],
      "id": "GzbTVa99v_s_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGdcZBjClMZ_"
      },
      "source": [
        "'''dummy_param takes a word as parameter and returns the same word\n",
        "   This function is useful when the sentences are already tokenized\n",
        "   and these tokenized sentences are given as input to \n",
        "   CountVectorizer() and TfidfVectorizer() for creating BOW and TF-IDF'''\n",
        "def dummy_param(doc):\n",
        "    return doc\n",
        "\n",
        "'''since the labels and sentences of test set are in different files (dataframes)\n",
        "   both these dataframes are merged to form test dataset'''\n",
        "test_df_sub = pd.merge(test_df[['Unnamed: 0','processed']], true_df[['Unnamed: 0','Sentiment']], on='Unnamed: 0')\n",
        "test_df_sub.rename(columns = {\"Sentiment\": \"sentiment\"}, inplace=True)\n",
        "\n",
        "'''converting text to word count vectors - BOW\n",
        "   tokenizer and preprocessor - are set to callable function which takes a word and return the same word\n",
        "                                since the sentences are already tokenized, parameters  \n",
        "   ngrame_range - (1,3) considers unigram, bigram and trigram'''\n",
        "cv = CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3), tokenizer = dummy_param, analyzer=\"word\", preprocessor=dummy_param)\n",
        "cv_train = cv.fit_transform(train_df_sub['processed'])\n",
        "cv_test = cv.transform(test_df_sub['processed'])\n",
        "\n",
        "'''Convert a collection of raw documents to a matrix of TF-IDF features\n",
        "   tokenizer and preprocessor - are set to callable function which takes a word and return the same word\n",
        "                                since the sentences are already tokenized, parameters  \n",
        "   ngrame_range - (1,3) considers unigram, bigram and trigram'''\n",
        "training_text = pd.Series([sent for sent in train_df_sub['pre_tokens']])\n",
        "training_target = pd.Series([label for label in train_df_sub['overall_sentiment']])\n",
        "tv = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1, 3), analyzer='word', tokenizer=dummy_param, preprocessor=dummy_param)\n",
        "training_tfidf = tv.fit_transform(training_text)\n",
        "\n",
        "#preparing testing dataset from the test dataframe\n",
        "testing_text = pd.Series([sent for sent in test_df_sub['processed']])\n",
        "testing_target = pd.Series([label for label in test_df_sub['sentiment']])\n",
        "testing_tfidf = tv.transform(testing_text)\n",
        "\n",
        "#creating an object for RandomOverSampler for random oversampling\n",
        "ros = RandomOverSampler(random_state=777)\n",
        "\n",
        "#creating an object for SMOTE for SMOTE oversampling\n",
        "smt = SMOTE(random_state=777, k_neighbors=5)\n"
      ],
      "id": "iGdcZBjClMZ_",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evyqF3JOw0tM",
        "outputId": "e2d8efc3-cd7a-4ee9-c9db-48d6a7eefa66"
      },
      "source": [
        "samplings = {'No Sampling':'no_sampling', 'ROS':ros, 'SMOTE':smt}\n",
        "representations = {'TFIDF':training_tfidf, 'BOW':cv_train}\n",
        "\n",
        "#this loop runs for 3 times for each of - No Sampling, ROS, SMOTE\n",
        "for sampling_key in samplings:\n",
        "  sampling = samplings[sampling_key]\n",
        "\n",
        "  #this loop runs twice for each of the above sampling technique with tfidf features and bow separately\n",
        "  for representation_key in representations:\n",
        "    representation = representations[representation_key]\n",
        "\n",
        "    #stratified k fold is used to have balanced number of labels in each of the folds\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
        "    accuracy = []\n",
        "    precision = []\n",
        "    recall = []\n",
        "    f1 = []\n",
        "\n",
        "    X = representation\n",
        "    Y = training_target\n",
        "\n",
        "    average_method = 'macro'\n",
        "    model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=42)\n",
        "\n",
        "    #for each of k folds, model is trained with train fold and tested with test fold\n",
        "    #precision, recall, f1 and accuracy are performance measures\n",
        "    for train, test in kfold.split(X, Y):\n",
        "\n",
        "        #to decide whether to perform oversampling for train dataset or not\n",
        "        if sampling =='no_sampling':\n",
        "          X_train = representation\n",
        "          y_train = training_target\n",
        "        else:\n",
        "          X_train, y_train = sampling.fit_sample(X[train], Y[train])\n",
        "          \n",
        "        model.fit(X_train, y_train)\n",
        "        prediction = model.predict(X[test])\n",
        "        scores = model.score(X[test],Y[test])\n",
        "        \n",
        "        accuracy.append(scores * 100)\n",
        "        precision.append(precision_score(Y[test], prediction, average=average_method)*100)\n",
        "        recall.append(recall_score(Y[test], prediction, average=average_method)*100)\n",
        "        f1.append(f1_score(Y[test], prediction, average=average_method)*100)\n",
        "\n",
        "    print(\"Representation: {} | Sampling: {}\".format(representation_key, sampling_key))\n",
        "    print(\"\\nTrain dataset\")\n",
        "    print(\"accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
        "    print(\"precision: %.2f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
        "    print(\"recall: %.2f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
        "    print(\"f1 score: %.2f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))\n",
        "\n",
        "    #to select the feature extraction method for test set\n",
        "    print(\"\\nTest dataset\")\n",
        "    if representation_key == 'TFIDF':\n",
        "      X_test = testing_tfidf\n",
        "    else:\n",
        "      X_test = cv_test\n",
        "    y_test = testing_target\n",
        "\n",
        "    prediction = model.predict(X_test)\n",
        "    scores = model.score(X_test,y_test)\n",
        "    print(\"Accuracy: %.2f%%\" % (scores * 100))\n",
        "    print(\"precision: %.2f%%\" % (precision_score(y_test, prediction, average=average_method)*100))\n",
        "    print(\"recall: %.2f%%\" % (recall_score(y_test, prediction, average=average_method)*100))\n",
        "    print(\"f1 score: %.2f%%\" % (f1_score(y_test, prediction, average=average_method)*100))\n",
        "    print(\"-\"*100)"
      ],
      "id": "evyqF3JOw0tM",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Representation: TFIDF | Sampling: No Sampling\n",
            "\n",
            "Train dataset\n",
            "accuracy: 83.56% (+/- 0.33%)\n",
            "precision: 59.21% (+/- 0.15%)\n",
            "recall: 58.86% (+/- 0.37%)\n",
            "f1 score: 58.13% (+/- 0.31%)\n",
            "\n",
            "Test dataset\n",
            "Accuracy: 57.17%\n",
            "precision: 30.19%\n",
            "recall: 33.33%\n",
            "f1 score: 28.02%\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Representation: BOW | Sampling: No Sampling\n",
            "\n",
            "Train dataset\n",
            "accuracy: 95.29% (+/- 0.78%)\n",
            "precision: 97.55% (+/- 0.37%)\n",
            "recall: 90.57% (+/- 1.37%)\n",
            "f1 score: 93.60% (+/- 1.00%)\n",
            "\n",
            "Test dataset\n",
            "Accuracy: 57.93%\n",
            "precision: 35.72%\n",
            "recall: 33.28%\n",
            "f1 score: 26.61%\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Representation: TFIDF | Sampling: ROS\n",
            "\n",
            "Train dataset\n",
            "accuracy: 54.66% (+/- 0.90%)\n",
            "precision: 36.12% (+/- 3.01%)\n",
            "recall: 34.45% (+/- 0.82%)\n",
            "f1 score: 32.77% (+/- 1.30%)\n",
            "\n",
            "Test dataset\n",
            "Accuracy: 48.53%\n",
            "precision: 32.78%\n",
            "recall: 32.85%\n",
            "f1 score: 32.48%\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Representation: BOW | Sampling: ROS\n",
            "\n",
            "Train dataset\n",
            "accuracy: 59.41% (+/- 0.04%)\n",
            "precision: 19.80% (+/- 0.01%)\n",
            "recall: 33.33% (+/- 0.00%)\n",
            "f1 score: 24.85% (+/- 0.01%)\n",
            "\n",
            "Test dataset\n",
            "Accuracy: 55.82%\n",
            "precision: 29.07%\n",
            "recall: 32.56%\n",
            "f1 score: 27.57%\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Representation: TFIDF | Sampling: SMOTE\n",
            "\n",
            "Train dataset\n",
            "accuracy: 48.61% (+/- 1.05%)\n",
            "precision: 34.70% (+/- 1.43%)\n",
            "recall: 34.65% (+/- 1.03%)\n",
            "f1 score: 34.11% (+/- 1.24%)\n",
            "\n",
            "Test dataset\n",
            "Accuracy: 48.10%\n",
            "precision: 33.11%\n",
            "recall: 33.21%\n",
            "f1 score: 32.94%\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Representation: BOW | Sampling: SMOTE\n",
            "\n",
            "Train dataset\n",
            "accuracy: 9.00% (+/- 0.00%)\n",
            "precision: 3.00% (+/- 0.00%)\n",
            "recall: 33.33% (+/- 0.00%)\n",
            "f1 score: 5.51% (+/- 0.00%)\n",
            "\n",
            "Test dataset\n",
            "Accuracy: 12.83%\n",
            "precision: 30.28%\n",
            "recall: 32.76%\n",
            "f1 score: 11.67%\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}